{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>sentinelTiler.ipynb </h1>\n",
    "\n",
    "Used to read in and augment sentinel 2 data, providing 128x128x3 image tiles that reflect the GSD of NICSAT.\n",
    "\n",
    "<b> General Info: </b>\n",
    "- https://stackoverflow.com/questions/55078484/open-jupyter-notebook-from-a-drive-other-than-c-drive For getting setup on this drive\n",
    "- https://www.youtube.com/watch?v=3kj8uoOlwjg for tutorial on reading in sentinel data\n",
    "- https://en.wikipedia.org/wiki/Sentinel-2 for Sentinel colour channels\n",
    "\n",
    "Sentinel 2 data can be accessed and downloaded from the <a href=\"https://www.copernicus.eu/en/accessing-data-where-and-how/conventional-data-access-hubs\">Copernicus Open Access hub</a>. (SCI Hub)\n",
    "\n",
    "Once downloaded, extract the files from the zip titled \"L2A_T*****_A******\", and place them in the designated srcPath.\n",
    "\n",
    "This code was ran using:\n",
    "\n",
    " GDAL: 3030100 \n",
    " Rasterio 3.3.1\n",
    " \n",
    " Multiple issues were encountered with implementing GDAL within the Conda environment (Python 3.9) The user may wish to attempt an install via pip instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Import Libraries </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries initalised. Version info:\n",
      " GDAL: 3030100 \n",
      " Rasterio 3.3.1\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import math\n",
    "\n",
    "from osgeo import gdal, osr\n",
    "#import gdal\n",
    "gdal.UseExceptions()\n",
    "\n",
    "import rasterio\n",
    "from rasterio import plot\n",
    "from rasterio.plot import show\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "# Masking libs\n",
    "#import shapefile as shp\n",
    "import seaborn as sns\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#import libtiff\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "\n",
    "print('libraries initalised. Version info:\\n GDAL:',gdal.VersionInfo(),'\\n Rasterio',rasterio.gdal_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-203b0bf1dcb7>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-203b0bf1dcb7>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    print(\"Accessing Data from:\", srcPath, \"\\nStoring temp files to:\" tmpPath)\u001b[0m\n\u001b[1;37m                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Establish variables\n",
    "srcPath = 'F:/_code/data/toread/'\n",
    "tmpPath = 'F:/_code/data/tmp/'\n",
    "\n",
    "training = True\n",
    "imWidth = 128\n",
    "imHeight = 128\n",
    "\n",
    "print(\"Accessing Data from:\", srcPath, \"\\nStoring temp files to:\" tmpPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty temp folder to rid last iteration products\n",
    "tmpFiles = glob.glob(tmpPath+'*')\n",
    "\n",
    "for file in tmpFiles:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2/\n"
     ]
    }
   ],
   "source": [
    "# define which subfolder to read for either training or testing\n",
    "if training:\n",
    "    trainVar = \"L2/\"\n",
    "    \n",
    "else:\n",
    "    trainVar = \"tst/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Level 2A Sentinel Products </h4>\n",
    "\n",
    "Level 2 products come preporcessed with the Sen2Cor algorithm, so can bypass this part of preprocessing.\n",
    "\n",
    "Their TOA (Top of Atmosphere) reflectance value have been adjusted to represent BOA (Bottom of Atmosphere) values.\n",
    "\n",
    "Sen2Cor is available from within QGIS software, or aviualbale from ESA's Science Toolbox.\n",
    "\n",
    "https://www.qgis.org/en/site/forusers/download.html\n",
    "https://step.esa.int/main/snap-supported-plugins/sen2cor/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/_code/data/toread/\n",
      "\n",
      " Files Found:\n",
      " ['F:\\\\_code\\\\data\\\\toread\\\\L2\\\\L2A_T28UGD_A022071_20210528T115400\\\\IMG_DATA\\\\R10m', 'F:\\\\_code\\\\data\\\\toread\\\\L2\\\\L2A_T29TQJ_A022614_20210705T110816\\\\IMG_DATA\\\\R10m', 'F:\\\\_code\\\\data\\\\toread\\\\L2\\\\L2A_T29ULU_A022071_20210528T115400\\\\IMG_DATA\\\\R10m', 'F:\\\\_code\\\\data\\\\toread\\\\L2\\\\L2A_T29UQR_A031208_20210613T112447\\\\IMG_DATA\\\\R10m', 'F:\\\\_code\\\\data\\\\toread\\\\L2\\\\L2A_T30TVP_A022614_20210705T110816\\\\IMG_DATA\\\\R10m', 'F:\\\\_code\\\\data\\\\toread\\\\L2\\\\L2A_T30TVS_A022328_20210615T111721\\\\IMG_DATA\\\\R10m', 'F:\\\\_code\\\\data\\\\toread\\\\L2\\\\L2A_T32TLL_A031522_20210705T102652\\\\IMG_DATA\\\\R10m', 'F:\\\\_code\\\\data\\\\toread\\\\L2\\\\L2A_T33SUD_A031536_20210706T095401\\\\IMG_DATA\\\\R10m']\n"
     ]
    }
   ],
   "source": [
    "# set up file paths for inputs\n",
    "# get all Bxx.jp2 files from directories\n",
    "L2srcPath = glob.glob(srcPath +  trainVar+'/*/')\n",
    "L2inPath =  glob.glob(srcPath + trainVar+ '/*/IMG_DATA/R10m/')\n",
    "L2inFiles = [os.path.normpath(pth) for pth in L2inPath]\n",
    "print('\\nFiles Found:\\n\\n',L2inFiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note, this only works for level 2A products, which have been adjusted for BOA reflectance, rather than TOA...\n",
    "\n",
    "iter = 0\n",
    "if iter < len(L2inFiles):\n",
    "    for folder in L2srcPath:\n",
    "    \n",
    "        # import RGB channels from S2 image data. (S2 has 12 bands, we only need 3 for RGB)\n",
    "        fileR = [os.path.normpath(pth) for pth in glob.glob(L2inPath[iter]+'*_B02_10m.jp2',recursive=False)]\n",
    "        fileG = [os.path.normpath(pth) for pth in glob.glob(L2inPath[iter]+'*_B03_10m.jp2',recursive=False)]\n",
    "        fileB = [os.path.normpath(pth) for pth in glob.glob(L2inPath[iter]+'*_B04_10m.jp2',recursive=False)]\n",
    "        bandR = rasterio.open(fileR[0], driver = 'JP2OpenJPEG')\n",
    "        bandG = rasterio.open(fileG[0], driver = 'JP2OpenJPEG')\n",
    "        bandB = rasterio.open(fileB[0], driver = 'JP2OpenJPEG')\n",
    "        iter = iter + 1\n",
    "        \n",
    "        # formulate a tif RGB image using the three seperate band channels\n",
    "        # as all bands have the same parameters, we can just use a given band to establish the TIF image.\n",
    "        today = datetime.today()\n",
    "        outName = today.strftime('IMG_SN_L2_%Y%m%d%H%M%S.tiff')\n",
    "        with rasterio.open(tmpPath+outName,'w',driver='GTiff',\n",
    "                          width = bandR.width, height = bandR.height,\n",
    "                          count = 3,\n",
    "                          crs=bandR.crs,\n",
    "                          transform=bandR.transform,\n",
    "                          dtype=bandR.dtypes[0]\n",
    "                         ) as src:\n",
    "\n",
    "            src.write(bandR.read(1),3) # red band (inversed RGB)\n",
    "            src.write(bandG.read(1),2) # green band (inversed RGB)\n",
    "            src.write(bandB.read(1),1) # blue band (inversed RGB)\n",
    "            src.close()\n",
    "            \n",
    "        bandR.close()\n",
    "        bandG.close()\n",
    "        bandB.close()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Level 1C Sentinel Products </h4>\n",
    "TOA reflectance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# set up file paths for inputs\n",
    "# get all Bxx.jp2 files from directories\n",
    "L1srcPath = glob.glob(srcPath + 'L1/*/')\n",
    "L1inPath =  glob.glob(srcPath + 'L1/*/IMG_DATA/')\n",
    "L1inFiles = [os.path.normpath(pth) for pth in L1inPath]\n",
    "print('\\n Files Found:\\n',L1inFiles)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Note, this only works for level1C products\n",
    "\n",
    "iter = 0\n",
    "if iter < len(L1inFiles):\n",
    "    for folder in L1srcPath:\n",
    "    \n",
    "        # import RGB channels from S2 image data. (S2 has 12 bands, we only need 3 for RGB)\n",
    "        fileR = [os.path.normpath(pth) for pth in glob.glob(L1inPath[iter]+'*_B02.jp2',recursive=False)]\n",
    "        fileG = [os.path.normpath(pth) for pth in glob.glob(L1inPath[iter]+'*_B03.jp2',recursive=False)]\n",
    "        fileB = [os.path.normpath(pth) for pth in glob.glob(L1inPath[iter]+'*_B04.jp2',recursive=False)]\n",
    "        bandR = rasterio.open(fileR[0], driver = 'JP2OpenJPEG')\n",
    "        bandG = rasterio.open(fileG[0], driver = 'JP2OpenJPEG')\n",
    "        bandB = rasterio.open(fileB[0], driver = 'JP2OpenJPEG')\n",
    "        iter = iter + 1\n",
    "        \n",
    "        # formulate a tif RGB image using the three seperate band channels\n",
    "        # as all bands have the same parameters, we can just use a given band to establish the TIF image.\n",
    "        today = datetime.today()\n",
    "        outName = today.strftime('IMG_SN_L1_%Y%m%d%H%M%S.tiff')\n",
    "        with rasterio.open(tmpPath+outName,'w',driver='GTiff',\n",
    "                          width = bandR.width, height = bandR.height,\n",
    "                          count = 3,\n",
    "                          crs=bandR.crs,\n",
    "                          transform=bandR.transform,\n",
    "                          dtype=bandR.dtypes[0]\n",
    "                         ) as src:\n",
    "\n",
    "            src.write(bandR.read(1),3) # red band (inversed RGB)\n",
    "            src.write(bandG.read(1),2) # green band (inversed RGB)\n",
    "            src.write(bandB.read(1),1) # blue band (inversed RGB)\n",
    "            src.close()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>NICSAT Image Specificiation</h2>\n",
    "\n",
    "Now that we have the image represented as an RGB tiff file, we need to augment it to reflect NICSAT's imaging system. An overview of the camera specification is given below.\n",
    "<p>\n",
    "\n",
    "<table style=\"width:100%\"; table align=\"left\">\n",
    "    \n",
    "    <tr> \n",
    "        <th>Parameter   <\\th>\n",
    "        <th colspan=\"1\"> Sentinel-2 </th>\n",
    "        <th colspan=\"1\"> NICSAT </th>\n",
    "        \n",
    "\n",
    "  <tr>\n",
    "    <td>GSD</td>\n",
    "      <td>10m @ 786km</td>\n",
    "    <td>42.9m @ 550km &#9733;</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Swath Width</td>\n",
    "      <td>290km @ 786km</td>\n",
    "    <td>88km @ 550km</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Spectral Resolution</td>\n",
    "      <td>12 Channel</td>\n",
    "   <td>R,G,B</td>\n",
    "   \n",
    "  </tr>\n",
    "    <tr>\n",
    "   <td>Focal Length</td>\n",
    "   <td>600mm </td>\n",
    "        <td>70mm</td>\n",
    "   \n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>F-No.</td>\n",
    "      <td>F4 (calculated)</td>\n",
    "   <td>F4</td>\n",
    "   \n",
    "  </tr>\n",
    "   <tr>\n",
    "   <td>MTF</td>\n",
    "       <td><a href=\"https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-2-msi/performance\">0.15 to 0.3</a></td>\n",
    "   <td>~40%</td>\n",
    "   \n",
    "  </tr>\n",
    "    <tr>\n",
    "   <td>SNR</td>\n",
    "        <td><a href=\"https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/resolutions/radiometric\">142-168</a></td>\n",
    "   <td>80-90 &#9733 &#9733</td>\n",
    "   \n",
    "  </tr>\n",
    "</table>\n",
    "</p>\n",
    "<p>\n",
    "<br>\n",
    "<h4> Notes: </h4>\n",
    "\n",
    "&#9733; (66m when in de-bayered mode)\n",
    "<br>\n",
    "&#9733; &#9733; Typical SNR for a clear scene at AM1.5 standard illumination and 0.3 albedo: 80-90\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>GSD Augmentation </h4>\n",
    "\n",
    "First, we need to reduce the GSD to reflect the NICSAT System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open tifs for augmenting in the augment folder\n",
    "scaleFactor = 0.2331 # scaling factor for 42.9m GSD\n",
    "#scaleFactor = 1 # scaling factor for GSD\n",
    "\n",
    "# define output file names\n",
    "augPath = glob.glob(tmpPath+'*')\n",
    "augFiles = [os.path.normpath(pth) for pth in augPath]\n",
    "\n",
    "\n",
    "\n",
    "for file in augFiles:\n",
    "    with rasterio.open(file) as src:\n",
    "    \n",
    "        # resample data\n",
    "        imgData = src.read(\n",
    "            out_shape = (src.count, int(src.height * scaleFactor), int(src.width * scaleFactor)),\n",
    "            resampling = Resampling.bilinear\n",
    "        )\n",
    "    \n",
    "        today = datetime.today()\n",
    "        outName = today.strftime('GSD_IMG_SN_%Y%m%d%H%M%S.tiff')\n",
    "        with rasterio.open(tmpPath+outName,'w',driver='GTiff',\n",
    "                          width = src.width, height = src.height,\n",
    "                          count = 3,\n",
    "                          crs=src.crs,\n",
    "                          transform = src.transform,\n",
    "                          dtype=src.dtypes[0]\n",
    "                         ) as outp:\n",
    "\n",
    "            outp.write(imgData) # red band (inversed RGB)\n",
    "            outp.close()\n",
    "            \n",
    "        src.close()\n",
    "        os.remove(file) # delete source file from previous step (saves drive space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Sea-Land Segmentation</h4>\n",
    "\n",
    "Uses a buffered land-mask shape file to subtract land from input images, leaving only sea behind. Buffering used to remove beaches/piers.\n",
    "\n",
    "Current buffer size is 1km using the 1kb shapefile that was created using QGIS software. It was assumed that terrestrial surveillance technologies (coastal radar, AIS, patrols) would manage to survey close inland waters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shapefile for land masking\n",
    "shpPath = \"spprt/shp/ecs_1kb.shp\"\n",
    "shapeFile = gpd.read_file(shpPath)\n",
    "\n",
    "inPath = glob.glob(tmpPath+'*')\n",
    "inFiles = [os.path.normpath(pth) for pth in inPath]\n",
    "\n",
    "for file in inFiles:\n",
    "    today = datetime.today()\n",
    "    # coordinate system alignment https://epsg.io/\n",
    "    ds_crs ='EPSG:3035'     # desired crs type (same as shapefile to perform crop).\n",
    "    im_out = tmpPath+today.strftime('MSK_IMG_SN_%Y%m%d%H%M%S.tiff')           # output image file (set to overwrite input file to save space)\n",
    "    \n",
    "    with rasterio.open(file) as imagery:\n",
    "        \n",
    "        tf, x, y = calculate_default_transform(imagery.crs, ds_crs, imagery.width, imagery.height, *imagery.bounds)\n",
    "        kwargs = imagery.meta.copy()\n",
    "        kwargs.update({'crs': ds_crs, 'transform': tf, 'width': x, 'height': y})\n",
    "        \n",
    "        with rasterio.open(im_out, 'w', **kwargs) as dst:\n",
    "            for i in range(1, imagery.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(imagery, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=imagery.transform,\n",
    "                    src_crs=imagery.crs,\n",
    "                    dst_transform=tf,\n",
    "                    dst_crs=ds_crs,\n",
    "                    resampling=Resampling.nearest)\n",
    "            dst.close()\n",
    "        imagery.close()\n",
    "    \n",
    "                \n",
    "    # clip raster\n",
    "    with fiona.open(shpPath) as shapeFile:\n",
    "        shapes = [feature[\"geometry\"] for feature in shapeFile]\n",
    "        shapeFile.close()\n",
    "        \n",
    "    # read img\n",
    "    with rasterio.open(im_out) as src:\n",
    "        out_image, out_tf = rasterio.mask.mask(src, shapes, invert=True, pad=True)\n",
    "        out_meta = src.meta\n",
    "        src.close()\n",
    "        \n",
    "    # save clipped img\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                    \"height\": out_image.shape[1],\n",
    "                    \"width\": out_image.shape[2],\n",
    "                    \"transform\": out_tf})\n",
    "    \n",
    "    with rasterio.open(im_out,\"w\",**out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "        dest.close()\n",
    "     \n",
    "    os.remove(file) # delete source file from previous step (saves drive space)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add photometric interpretation (tag262)\n",
    "\n",
    "inPath = glob.glob(tmpPath+'*')\n",
    "inFiles = [os.path.normpath(pth) for pth in inPath]\n",
    "\n",
    "for file in inFiles:\n",
    "    comstring = (\"tiffset -s 262 1 \" + file)\n",
    "    os.system(comstring)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tiffs to 8bit pngs (saves drive space, but sacrifices 16bit colour channels)\n",
    "inPath = glob.glob(tmpPath+'*')\n",
    "outPath = 'F:/_code/data/tiles/pngs/'\n",
    "\n",
    "inFiles = [os.path.normpath(pth) for pth in inPath]\n",
    "i = 0\n",
    "for file in inFiles:\n",
    "    name = \"{0:0=5d}\".format(i)\n",
    "    print('PNG Conversion in progress. File', i, 'of', len(inFiles), '.\\n  File:', file, '(IN PROGRESS)')\n",
    "    img = imageio.imread(file)\n",
    "\n",
    "    img_norm = np.zeros((img.shape))   \n",
    "    beta = 4*(img.ptp() / math.sqrt(img.std()))\n",
    "    \n",
    "    try:\n",
    "        img_norm = cv2.normalize(img, img_norm, 0, beta, cv2.NORM_MINMAX, cv2.CV_8UC3)\n",
    "        fileName = outPath + str(name) + '.png'\n",
    "        imageio.imwrite(fileName, img_norm)\n",
    "        print('  File:', file, '(COMPLETE)\\n')\n",
    "        \n",
    "    except:\n",
    "        print('  File:', file, '(FAILED)\\n')\n",
    "              \n",
    "    i = i+1\n",
    "    img = [] # clear img\n",
    "    img_norm = []\n",
    "print('Operation Succeded. ', i, 'files converted.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from GitHub:\n",
    "# https://github.com/Devyanshu/image-split-with-overlap/blob/master/split_image_with_overlap.py\n",
    "\n",
    "inPath = 'F:/_code/data/tiles/pngs/'\n",
    "inPath = glob.glob(inPath+'*')\n",
    "inFiles = [os.path.normpath(pth) for pth in inPath]\n",
    "print(inFiles)\n",
    "outPath = 'F:/_code/data/tiles/128tiles/'\n",
    "\n",
    "# empty existing tiles\n",
    "tmpFiles = glob.glob(outPath+'*')\n",
    "for file in tmpFiles:\n",
    "    os.remove(file)\n",
    "\n",
    "def start(size, split_size, overlap=0):\n",
    "    \n",
    "    points = []\n",
    "    \n",
    "    print(size, split_size, overlap)\n",
    "    stride = (split_size * (1-overlap))\n",
    "    stride = int(stride)\n",
    "    counter = 1\n",
    "    \n",
    "    while True:\n",
    "        pt = stride * counter\n",
    "        \n",
    "        if pt + split_size >= size:\n",
    "            points.append(size - split_size)\n",
    "            break\n",
    "        else:\n",
    "            points.append(pt)\n",
    "        counter += 1\n",
    "    return points\n",
    "\n",
    "split_width = imWidth\n",
    "split_height = imHeight\n",
    "\n",
    "count = 0\n",
    "name = 'split_'\n",
    "frmt = '.png'\n",
    "\n",
    "for file in inFiles:\n",
    "    img = cv2.imread(file)\n",
    "    img_h, img_w, bnds = img.shape\n",
    "\n",
    "    X_points = start(img_w, split_width, 0.1)\n",
    "    Y_points = start(img_h, split_height, 0.1)\n",
    "    for i in Y_points:\n",
    "        for j in X_points:\n",
    "            split = img[i:i+split_height, j:j+split_width]\n",
    "            fileName = outPath + file[25:-4] + '_{}{}{}'.format(name,count,frmt)\n",
    "            cv2.imwrite(fileName, split)\n",
    "            count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete images which are mostly black (performed by investigating file size)\n",
    "# This may need to be adjusted depending on source image / resolution\n",
    "\n",
    "inPath = 'F:/_code/data/tiles/128tiles/'\n",
    "inPath = glob.glob(inPath+'*')\n",
    "inFiles = [os.path.normpath(pth) for pth in inPath]\n",
    "\n",
    "for file in inFiles:\n",
    "    f_size = os.stat(file).st_size\n",
    "    if f_size <1200:  # 1.9kB\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty temp folder after completion (saves drive space)\n",
    "tmpFiles = glob.glob(tmpPath+'*')\n",
    "\n",
    "for file in tmpFiles:\n",
    "    os.remove(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Export Data </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import imageio\n",
    "import PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function for randomly rotating an image by 90 degrees for augmentation\n",
    "# declare variables\n",
    "dataset = []\n",
    "\n",
    "# declare functions\n",
    "\n",
    "def create_dataset(source):     # function for producing a dataset by reading image data as an array, and appending it to an array ready for serialisation\n",
    "    \n",
    "    for img in source:\n",
    "        \n",
    "        img_array = cv2.imread(img)  # read in png into array\n",
    "        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "        dataset.append(img_array)\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "def orthogonal_rot(image):     # simple function for rotating an image by a random choice of 0, 90, or -90 degrees\n",
    "    \n",
    "    return np.rot90(image, np.random.choice([-1, 0, 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# export images\n",
    "\n",
    "src_path = glob.glob(\"F:/_code/data/tiles/train/*\")\n",
    "img_size = imWidth\n",
    "channels = 3\n",
    "\n",
    "ds = create_dataset(src_path)\n",
    "data = np.array(ds).reshape(-1, img_size, img_size, channels).astype(np.float32)\n",
    "#data_out = data[0, :, :, :]\n",
    "\n",
    "# save the data for usage later\n",
    "pickle_out = open(\"seaTiles.pickle\", \"wb\")\n",
    "pickle.dump(data, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform augmentation\n",
    "outpth = \"F:/_code/data/128Aug/train/\"\n",
    "from tensorflow.keras.preprocessing import image as tfi\n",
    "def data_augment(fileIn, nameint, counter=100):\n",
    "    img = cv2.imread(fileIn)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.uint8) \n",
    "    img = np.expand_dims(img, axis=0) # convert to a 4D tensor\n",
    "    \n",
    "    # construct image gernerator for augmentation\n",
    "    augr = ImageDataGenerator(\n",
    "        zoom_range=[1,1],\n",
    "        preprocessing_function=orthogonal_rot,\n",
    "        fill_mode=\"wrap\",\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=True,\n",
    "        channel_shift_range = 10)\n",
    "        #brightness_range = [0.3, 0.6])\n",
    "    \n",
    "    name = \"img\" + str(nameint).zfill(6)\n",
    "    name = str(name)\n",
    "    save_to_dir=outpth\n",
    "    #imageGen = augr.flow(img, batch_size=1, save_to_dir=outpth, save_prefix=name, save_format=\"png\")\n",
    "    imageGen = augr.flow(img, batch_size=1, save_format=\".png\")\n",
    "    i = 0\n",
    "    for batch in imageGen:\n",
    "        img_sv = tfi.array_to_img(batch[0],scale=False)\n",
    "        img_sv.save(save_to_dir + name + fr\"_{i}.png\")\n",
    "        if (i == sampleNo - 1):\n",
    "            break\n",
    "        i +=1\n",
    "    \n",
    "    total = 0\n",
    "    for image in imageGen:\n",
    "        total += 1\n",
    "        if total == counter:\n",
    "            break\n",
    "    \n",
    "\n",
    "print(PIL.__version__)  # an error can happem with brightness range if PIL is 8.3.0...          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = glob.glob(\"F:/_code/GitHub/IRP/data/128/train_new/*\")\n",
    "print(len(src_path))\n",
    "sampleNo = 5\n",
    "count = 0\n",
    "for file in src_path:\n",
    "    \n",
    "    data_augment(file, count, sampleNo)\n",
    "    count = count + 1\n",
    "    \n",
    "print('All Images Augmented.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# export images\n",
    "imWidth = 56\n",
    "\n",
    "src_path = glob.glob(\"F:/_code/GitHub/IRP/data/test/boats/*\")\n",
    "img_size = imWidth\n",
    "channels = 3\n",
    "\n",
    "ds = create_dataset(src_path)\n",
    "data = np.array(ds).reshape(-1, img_size, img_size, channels).astype(np.float32)\n",
    "#data_out = data[0, :, :, :]\n",
    "\n",
    "\n",
    "# save the data for usage later\n",
    "pickle.HIGHEST_PROTOCOL\n",
    "pickle_out = open(\"seaTiles.pickle\", \"wb\")\n",
    "pickle.dump(data, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRP_v2",
   "language": "python",
   "name": "irp_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
